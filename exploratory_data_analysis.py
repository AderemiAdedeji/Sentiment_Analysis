# -*- coding: utf-8 -*-
"""Exploratory Data Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RIH4QTCWe6R0J160D8Znvo4gLdOrAzMC
"""

import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter
from wordcloud import WordCloud, STOPWORDS
import spacy
import re

preprocessed_reddit_posts = pd.read_csv('preprocessed_reddit_posts.csv')
preprocessed_twitter_tweets = pd.read_csv('preprocessed_twitter_tweets.csv')

# Summary statistics for Reddit data
preprocessed_reddit_posts.describe()

# Information about Reddit posts
preprocessed_reddit_posts.info()

# Summary statistics for Twitter tweets
preprocessed_twitter_tweets.describe()

# Info about Twitter tweets data
preprocessed_twitter_tweets.info()

plt.hist(preprocessed_reddit_posts['score'])
plt.title('Distribution of Reddit post scores')
plt.xlabel('Score')
plt.ylabel('Count')
plt.show()

plt.scatter(preprocessed_reddit_posts['score'], preprocessed_reddit_posts['num_comments'])
plt.title('Reddit post scores vs. number of comments')
plt.xlabel('Score')
plt.ylabel('Number of comments')
plt.show()

# Concatenate the title and body columns from the reddit posts df with the tweet_text column from the twitter tweets df
merged_df = pd.concat([preprocessed_reddit_posts["title"] + " " + preprocessed_reddit_posts["body"], preprocessed_twitter_tweets["tweet_text"]])

# Define a regular expression pattern to match unwanted characters
unwanted_pattern = r"[!@&\\.;:,/\|()_{}\"\'\[\]]"

word_counter = Counter()
for text in merged_df:
  # Use regular expressions to remove unwanted characters
  text_words = re.sub(unwanted_pattern, "", text)
  # Split the text into individual words
  text_words = text_words.split()
  # Exclude words that are too short
  text_words = [w for w in text_words if len(w) > 3]
  # Exclude unwanted words
  text_words = [w for w in text_words if w not in ["amp"]]
  word_counter.update(text_words)

from wordcloud import WordCloud
cloud = WordCloud(width=800, height=400)
cloud.generate_from_frequencies(dict(word_counter.most_common(300)))
image = cloud.to_image()
image.save("wordcloud.png")

from wordcloud import WordCloud
from PIL import Image
import numpy as np

# Load logo image
logo_mask = np.array(Image.open("elephant.png"))

# Create WordCloud object
cloud = WordCloud(width=1000, height=400, mask=logo_mask)

# Generate wordcloud from word frequencies
cloud.generate_from_frequencies(dict(word_counter.most_common(300)))

# Convert to image
image = cloud.to_image()

# Save image
image.save("wordcloud1.png")

merged_df.to_csv('merged_df.csv')