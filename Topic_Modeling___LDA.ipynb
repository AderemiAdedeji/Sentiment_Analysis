{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## TOPIC MODELLING (LDA)"
      ],
      "metadata": {
        "id": "KC3AeZFCcvJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "2iidu8zacoIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "import gensim \n",
        "import gensim.corpora as corpora \n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "fBl2cHpxc3wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data from CSV files\n",
        "preprocessed_reddit_posts = pd.read_csv('preprocessed_reddit_posts.csv') \n",
        "preprocessed_twitter_tweets = pd.read_csv('preprocessed_twitter_tweets.csv')\n",
        "\n",
        "# Concatenate the title and body columns from the reddit DataFrame with the tweet_text column from the twitter DataFrame\n",
        "merged_df = pd.concat([preprocessed_reddit_posts['title'] + ' ' + preprocessed_reddit_posts['body'], preprocessed_twitter_tweets['tweet_text']])"
      ],
      "metadata": {
        "id": "NEbhKs88dBD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of documents, where each document is a list of words\n",
        "documents = [text.split() for text in merged_df]\n",
        "\n",
        "# Create a dictionary from the documents\n",
        "vocab = corpora.Dictionary(documents)\n",
        "\n",
        "# Create a corpus from the documents\n",
        "corpus = [vocab.doc2bow(text) for text in documents]\n",
        "\n",
        "# Train an LDA model on the corpus\n",
        "num_topics = 10\n",
        "lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=vocab, num_topics=num_topics)\n",
        "\n",
        "# Print the topics\n",
        "topic_distribution = pprint(lda_model.print_topics())"
      ],
      "metadata": {
        "id": "YyrtY9w9dcSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(lda_model.get_document_topics(corpus))"
      ],
      "metadata": {
        "id": "RUYBElbwddeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# group the posts by title and count the number of comments per title\n",
        "grouped = preprocessed_reddit_posts.groupby('title')['num_comments'].sum().reset_index()\n",
        "\n",
        "# sort the posts by the number of comments in descending order\n",
        "grouped = grouped.sort_values(by='num_comments', ascending=False)\n",
        "\n",
        "# print the top 10 posts by the number of comments\n",
        "print(grouped.head(10))\n"
      ],
      "metadata": {
        "id": "X2VDw0pwdm0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topic_distribution_df = pd.DataFrame(topic_distribution, columns=['Topic ' + str(i+1) for i in range(num_topics)])\n",
        "topic_distribution_df['Dominant Topic'] = topic_distribution_df.idxmax(axis=1)\n",
        "\n",
        "topic_distribution_table = pd.concat([topic_distribution_df['Dominant Topic'].value_counts(normalize=True),\n",
        "                                      topic_distribution_df['Dominant Topic'].value_counts()], axis=1)\n",
        "topic_distribution_table.columns = ['Proportion of Comments', 'Number of Comments']\n",
        "topic_distribution_table.index.name = 'Topic'\n",
        "print(topic_distribution_table)"
      ],
      "metadata": {
        "id": "O9WFP9OGe29v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}